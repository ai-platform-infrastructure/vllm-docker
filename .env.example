COMPOSE_PROJECT_NAME=vllm_api
COMPOSE_DOMAIN=vllmapi.local.itkdev.dk

HUGGING_FACE_HUB_TOKEN=xxx

# Qwen3-Next-80B MoE with NVIDIA FP4 quantization for Blackwell RTX PRO 6000 (96GB VRAM)
# 64k context, high memory utilization
VLLM_MODEL=nvidia/Qwen3-Next-80B-A3B-Instruct-NVFP4
VLLM_OPTIONS=--dtype auto --max-model-len 65536 --gpu-memory-utilization 0.90 --tensor-parallel-size 1 --max-num-batched-tokens 8192 --disable-log-requests
SHM_SIZE=32gb

# Blackwell-optimized settings (FlashInfer attention and FP4 MoE kernels)
VLLM_ATTENTION_BACKEND=FLASHINFER
VLLM_USE_FLASHINFER_MOE_FP4=1

# Leave empty if you do not wish to use API key.
VLLM_API_KEY=